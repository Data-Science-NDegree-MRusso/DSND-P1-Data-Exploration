{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='part1'>StackOverflow Survey Data analysis</h2>\n",
    "\n",
    "\n",
    "A comparison of some [data from StackOverflow surveys](https://insights.stackoverflow.com/survey/), for the years from 2013 to 2020.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's read in the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's read in the data for the various years as DataFrames. You will have to change the paths accorfingly to your case. \n",
    "\n",
    "You can see that the files have different name formats and that some require some adjustments in loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data file path if needed\n",
    "df_13 = pd.read_csv('../data/stack_overflow_2013/2013 Stack Overflow Survey Responses.csv',dtype='string') #Uncomment for 2013\n",
    "df_14 = pd.read_csv('../data/stack_overflow_2014/2014 Stack Overflow Survey Responses.csv') #Uncomment for 2014\n",
    "df_15 = pd.read_csv('../data/stack_overflow_2015/2015 Stack Overflow Developer Survey Responses.csv',dtype='string') #Uncomment for 2015\n",
    "df_16 = pd.read_csv('../data/stack_overflow_2016/2016 Stack Overflow Survey Responses.csv') #Uncomment for 2016\n",
    "df_17 = pd.read_csv('../data/stack_overflow_2017/survey_results_public.csv') #Uncomment for 2017\n",
    "df_18 = pd.read_csv('../data/stack_overflow_2018/survey_results_public.csv',dtype='string') #Uncomment for 2018\n",
    "df_19 = pd.read_csv('../data/stack_overflow_2019/survey_results_public.csv') #Uncomment for 2019\n",
    "df_20 = pd.read_csv('../data/stack_overflow_2020/survey_results_public.csv') #Uncomment for 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some further cleaning is needed for some of the years - you can look on the original .csv to check out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2013, 2014 - get rid of first row\n",
    "df_13.drop(0, inplace = True)\n",
    "df_14.drop(0, inplace = True)\n",
    "\n",
    "# 2015 - rename columns and get rid of first row\n",
    "col_names_dict = {}\n",
    "\n",
    "for col in df_15.columns:\n",
    "    col_names_dict[col] = df_15[col][0]\n",
    "\n",
    "df_15.rename(columns = col_names_dict, inplace = True)\n",
    "df_15.drop(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can se the next cell to take a look at the datasets, their columns etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at any df you like\n",
    "df_16.head()\n",
    "# df_20.tail()\n",
    "\n",
    "# See details of the columns available\n",
    "# for col in df_16.columns:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.** As a first step, let's take a look at the # of rows and columns for the various years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_13 = df_13.shape[0] # rows, 2013\n",
    "num_cols_13 = df_13.shape[1] # columns, 2013\n",
    "\n",
    "num_rows_14 = df_14.shape[0] # rows, 2014\n",
    "num_cols_14 = df_14.shape[1] # columns, 2014\n",
    "\n",
    "num_rows_15 = df_15.shape[0] # rows, 2015\n",
    "num_cols_15 = df_15.shape[1] # columns, 2015\n",
    "\n",
    "num_rows_16 = df_16.shape[0] # rows, 2016\n",
    "num_cols_16 = df_16.shape[1] # columns, 2016\n",
    "\n",
    "num_rows_17 = df_17.shape[0] # rows, 2017\n",
    "num_cols_17 = df_17.shape[1] # columns, 2017\n",
    "\n",
    "num_rows_18 = df_18.shape[0] # rows, 2018\n",
    "num_cols_18 = df_18.shape[1] # columns, 2018\n",
    "\n",
    "num_rows_19 = df_19.shape[0] # rows, 2019\n",
    "num_cols_19 = df_19.shape[1] # columns, 2019\n",
    "\n",
    "num_rows_20 = df_20.shape[0] # rows, 2020\n",
    "num_cols_20 = df_20.shape[1] # columns, 2020\n",
    "\n",
    "print(\"Year 2013 - Rows in the dataset: \", num_rows_13, \"; Colums in the dataset: \", num_cols_13)\n",
    "print(\"Year 2014 - Rows in the dataset: \", num_rows_14, \"; Colums in the dataset: \", num_cols_14)\n",
    "print(\"Year 2015 - Rows in the dataset: \", num_rows_15, \"; Colums in the dataset: \", num_cols_15)\n",
    "print(\"Year 2016 - Rows in the dataset: \", num_rows_16, \"; Colums in the dataset: \", num_cols_16)\n",
    "print(\"Year 2017 - Rows in the dataset: \", num_rows_17, \"; Colums in the dataset: \", num_cols_17)\n",
    "print(\"Year 2018 - Rows in the dataset: \", num_rows_18, \"; Colums in the dataset: \", num_cols_18)\n",
    "print(\"Year 2019 - Rows in the dataset: \", num_rows_19, \"; Colums in the dataset: \", num_cols_19)\n",
    "print(\"Year 2020 - Rows in the dataset: \", num_rows_20, \"; Colums in the dataset: \", num_cols_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of `null` in the various years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_per_13 = df_13.isnull().sum().sum()/(num_rows_13*num_cols_13)\n",
    "null_per_14 = df_14.isnull().sum().sum()/(num_rows_14*num_cols_14)\n",
    "null_per_15 = df_15.isnull().sum().sum()/(num_rows_15*num_cols_15)\n",
    "null_per_16 = df_16.isnull().sum().sum()/(num_rows_16*num_cols_16)\n",
    "null_per_17 = df_17.isnull().sum().sum()/(num_rows_17*num_cols_17)\n",
    "null_per_18 = df_18.isnull().sum().sum()/(num_rows_18*num_cols_18)\n",
    "null_per_19 = df_19.isnull().sum().sum()/(num_rows_19*num_cols_19)\n",
    "null_per_20 = df_20.isnull().sum().sum()/(num_rows_20*num_cols_20)\n",
    "\n",
    "print (\"Year 2013 - Percentage of Null: \", \"{:.2f}\".format(null_per_13*100), \"%\")\n",
    "print (\"Year 2014 - Percentage of Null: \", \"{:.2f}\".format(null_per_14*100), \"%\")\n",
    "print (\"Year 2015 - Percentage of Null: \", \"{:.2f}\".format(null_per_15*100), \"%\")\n",
    "print (\"Year 2016 - Percentage of Null: \", \"{:.2f}\".format(null_per_16*100), \"%\")\n",
    "print (\"Year 2017 - Percentage of Null: \", \"{:.2f}\".format(null_per_17*100), \"%\")\n",
    "print (\"Year 2018 - Percentage of Null: \", \"{:.2f}\".format(null_per_18*100), \"%\")\n",
    "print (\"Year 2019 - Percentage of Null: \", \"{:.2f}\".format(null_per_19*100), \"%\")\n",
    "print (\"Year 2020 - Percentage of Null: \", \"{:.2f}\".format(null_per_20*100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.** Characterize professional categories (Professional Developer, Student etc.)\n",
    "\n",
    "**Note:** For this and the next analyses we'll focus on the last 4 years, given that they seem to present the more detailed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: title of the column containing professional information changed from 2017 to 2020\n",
    "status_vals_17 = df_17.Professional.value_counts() #2017\n",
    "# Data in 2018 do not seem to include this information, even if it was asked to the respondent\n",
    "status_vals_19 = df_19.MainBranch.value_counts() #2019\n",
    "status_vals_20 = df_20.MainBranch.value_counts() #2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of the proportion of individuals in each professional category \n",
    "fig, ((ax1, ax2, ax3)) = plt.subplots(1, 3)\n",
    "fig.suptitle(\"Developer characterization\")\n",
    "fig.set_figheight(9) \n",
    "fig.set_figwidth(19.2)\n",
    "\n",
    "(status_vals_17/(num_rows_17 - df_17.Professional.isnull().sum())).plot(ax=ax1, kind=\"bar\")\n",
    "ax1.set_title(\"2017\")\n",
    "ax1.set_ylim([0, 0.8])\n",
    "ax1.grid()\n",
    "\n",
    "(status_vals_19/(num_rows_19 - df_19.MainBranch.isnull().sum())).plot(ax=ax2, kind=\"bar\", color=\"purple\")\n",
    "ax2.set_title(\"2019\")\n",
    "ax2.set_ylim([0, 0.8])\n",
    "ax2.grid()\n",
    "\n",
    "(status_vals_20/(num_rows_20 - df_20.MainBranch.isnull().sum())).plot(ax=ax3, kind=\"bar\", color=\"green\")\n",
    "ax3.set_title(\"2020\")\n",
    "ax3.set_ylim([0, 0.8])\n",
    "ax3.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.** Characterize formal education of the Respondent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: title of the column containing formal education information changed from 2017 to 2020\n",
    "ed_vals_17 = df_17.FormalEducation.value_counts() #2017\n",
    "ed_vals_18 = df_18.FormalEducation.value_counts() #2018\n",
    "ed_vals_19 = df_19.EdLevel.value_counts() #2018\n",
    "ed_vals_20 = df_20.EdLevel.value_counts() #2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of the proportion of individuals in ed_vals\n",
    "# Split in 2 figures for readibility of the labels\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle(\"Formal Education (1/2)\")\n",
    "fig.set_figheight(9) \n",
    "fig.set_figwidth(12.8)\n",
    "\n",
    "(ed_vals_17[:5]/(num_rows_17 - df_17.FormalEducation.isnull().sum())).plot(ax=ax1, kind=\"bar\");\n",
    "ax1.set_title(\"2017\")\n",
    "ax1.set_ylim([0, 0.5])\n",
    "ax1.grid()\n",
    "\n",
    "(ed_vals_18[:5]/(num_rows_18 - df_18.FormalEducation.isnull().sum())).plot(ax=ax2, kind=\"bar\", color = \"orange\");\n",
    "ax2.set_title(\"2018\")\n",
    "ax2.set_ylim([0, 0.5])\n",
    "ax2.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in 2 figures for readibility of the labels\n",
    "fig, (ax3, ax4) = plt.subplots(1, 2)\n",
    "fig.suptitle(\"Formal Education (2/2)\")\n",
    "fig.set_figheight(9) \n",
    "fig.set_figwidth(12.8)\n",
    "\n",
    "(ed_vals_19[:5]/(num_rows_19 - df_19.EdLevel.isnull().sum())).plot(ax=ax3, kind=\"bar\", color = \"purple\");\n",
    "ax3.set_title(\"2019\")\n",
    "ax3.set_ylim([0, 0.5])\n",
    "ax3.grid();\n",
    "\n",
    "(ed_vals_20[:5]/(num_rows_20 - df_20.EdLevel.isnull().sum())).plot(ax=ax4, kind=\"bar\", color = \"green\");\n",
    "ax4.set_title(\"2020\")\n",
    "ax4.set_ylim([0, 0.5])\n",
    "ax4.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4.** Let's take a look at technologies (languages used etc.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to be used to parse the content on the various columns\n",
    "def total_count(df, col1, col2, separator):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - the pandas dataframe you want to search\n",
    "    col1 - the column name you want to look through\n",
    "    col2 - the column you want to count values from\n",
    "    look_for - a list of strings you want to search for in each row of df[col]\n",
    "    separator - separator between strings (comma, semicolon etc.)\n",
    "\n",
    "    OUTPUT:\n",
    "    new_df - a dataframe of each look_for with the count of how often it shows up\n",
    "    items_list - a list of the different items that were identified parsing the dataframe\n",
    "    '''\n",
    "    new_df = defaultdict(int)\n",
    "    items_list = [] \n",
    "\n",
    "    # loop through rows\n",
    "    for idx in range(df.shape[0]):\n",
    "        # Split the string to separate the various languages used by the responder (if > 1)\n",
    "        langs = df[col1][idx].split(separator)\n",
    "        # Loop in the list of items\n",
    "        for idy in range(len(langs)):\n",
    "            # Update counts in the dataframe\n",
    "            val = langs[idy]\n",
    "            new_df[val] += int(df[col2][idx])\n",
    "            # If not detected before update list            \n",
    "            if (not(val in items_list)):\n",
    "                items_list.append(val)\n",
    "                \n",
    "    new_df = pd.DataFrame(pd.Series(new_df)).reset_index()\n",
    "    new_df.columns = [col1, col2]\n",
    "    new_df.sort_values('count', ascending=False, inplace=True)\n",
    "    return new_df, items_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most used languages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_used_17 = df_17.HaveWorkedLanguage.value_counts() #2017\n",
    "lang_used_18 = df_18.LanguageWorkedWith.value_counts() #2018\n",
    "lang_used_19 = df_19.LanguageWorkedWith.value_counts() #2019\n",
    "lang_used_20 = df_20.LanguageWorkedWith.value_counts() #2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_17 = lang_used_17.reset_index()\n",
    "lu_18 = lang_used_18.reset_index()\n",
    "lu_19 = lang_used_19.reset_index()\n",
    "lu_20 = lang_used_20.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_17.rename(columns={'index': 'language', 'HaveWorkedLanguage': 'count'}, inplace=True)\n",
    "lu_18.rename(columns={'index': 'language', 'LanguageWorkedWith': 'count'}, inplace=True)\n",
    "lu_19.rename(columns={'index': 'language', 'LanguageWorkedWith': 'count'}, inplace=True)\n",
    "lu_20.rename(columns={'index': 'language', 'LanguageWorkedWith': 'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_17_df, worked_languages_17 = total_count(lu_17, 'language', 'count', '; ') # NOTE: separator for 2017 is different\n",
    "lu_18_df, worked_languages_18 = total_count(lu_18, 'language', 'count', ';')\n",
    "lu_19_df, worked_languages_19 = total_count(lu_19, 'language', 'count', ';')\n",
    "lu_20_df, worked_languages_20 = total_count(lu_20, 'language', 'count', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of the proportion of the top 10 languages/combinations for the individuals in count_vals\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "fig.suptitle(\"Languages Used\")\n",
    "fig.set_figheight(19) \n",
    "fig.set_figwidth(12.8)\n",
    "\n",
    "ax1.bar(lu_17_df[:10]['language'].to_list(), lu_17_df[:10]['count'].to_list()\n",
    "        /(num_rows_17 - df_17.HaveWorkedLanguage.isnull().sum()))\n",
    "ax1.tick_params('x', labelrotation=90)\n",
    "ax1.set_title(\"2017\")\n",
    "ax1.set_ylim([0, 0.8])\n",
    "ax1.grid()\n",
    "\n",
    "ax2.bar(lu_18_df[:10]['language'].to_list(), lu_18_df[:10]['count'].to_list()\n",
    "        /(num_rows_18 - df_18.LanguageWorkedWith.isnull().sum()), color = \"orange\")\n",
    "ax2.tick_params('x', labelrotation=90)\n",
    "ax2.set_title(\"2018\")\n",
    "ax2.set_ylim([0, 0.8])\n",
    "ax2.grid()\n",
    "\n",
    "ax3.bar(lu_19_df[:10]['language'].to_list(), lu_19_df[:10]['count'].to_list()\n",
    "        /(num_rows_19 - df_19.LanguageWorkedWith.isnull().sum()), color = \"purple\")\n",
    "ax3.tick_params('x', labelrotation=90)\n",
    "ax3.set_title(\"2019\")\n",
    "ax3.set_ylim([0, 0.8])\n",
    "ax3.grid()\n",
    "\n",
    "ax4.bar(lu_20_df[:10]['language'].to_list(), lu_20_df[:10]['count'].to_list()\n",
    "        /(num_rows_20 - df_20.LanguageWorkedWith.isnull().sum()), color = \"green\")\n",
    "ax4.tick_params('x', labelrotation=90)\n",
    "ax4.set_title(\"2020\")\n",
    "ax4.set_ylim([0, 0.8])\n",
    "ax4.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the languages people want to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_wanted_17 = df_17.WantWorkLanguage.value_counts() #2017\n",
    "lang_wanted_18 = df_18.LanguageDesireNextYear.value_counts() #2018\n",
    "lang_wanted_19 = df_19.LanguageDesireNextYear.value_counts() #2019\n",
    "lang_wanted_20 = df_20.LanguageDesireNextYear.value_counts() #2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_17 = lang_wanted_17.reset_index()\n",
    "lw_18 = lang_wanted_18.reset_index()\n",
    "lw_19 = lang_wanted_19.reset_index()\n",
    "lw_20 = lang_wanted_20.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_17.rename(columns={'index': 'language', 'WantWorkLanguage': 'count'}, inplace=True)\n",
    "lw_18.rename(columns={'index': 'language', 'LanguageDesireNextYear': 'count'}, inplace=True)\n",
    "lw_19.rename(columns={'index': 'language', 'LanguageDesireNextYear': 'count'}, inplace=True)\n",
    "lw_20.rename(columns={'index': 'language', 'LanguageDesireNextYear': 'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_17_df, wanted_languages_17 = total_count(lw_17, 'language', 'count', '; ')\n",
    "lw_18_df, wanted_languages_18 = total_count(lw_18, 'language', 'count', ';')\n",
    "lw_19_df, wanted_languages_19 = total_count(lw_19, 'language', 'count', ';')\n",
    "lw_20_df, wanted_languages_20 = total_count(lw_20, 'language', 'count', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of the proportion of the top 10 languages/combinations for the individuals in count_vals\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "fig.suptitle(\"Languages Wanted\")\n",
    "fig.set_figheight(19) \n",
    "fig.set_figwidth(12.8)\n",
    "\n",
    "ax1.bar(lw_17_df[:10]['language'].to_list(), lw_17_df[:10]['count'].to_list()\n",
    "        /(num_rows_17 - df_17.WantWorkLanguage.isnull().sum()))\n",
    "ax1.tick_params('x', labelrotation=90)\n",
    "ax1.set_title(\"2017\")\n",
    "ax1.set_ylim([0, 0.6])\n",
    "ax1.grid()\n",
    "\n",
    "ax2.bar(lw_18_df[:10]['language'].to_list(), lw_18_df[:10]['count'].to_list()\n",
    "        /(num_rows_18 - df_18.LanguageDesireNextYear.isnull().sum()), color = \"orange\")\n",
    "ax2.tick_params('x', labelrotation=90)\n",
    "ax2.set_title(\"2018\")\n",
    "ax2.set_ylim([0, 0.6])\n",
    "ax2.grid()\n",
    "\n",
    "ax3.bar(lw_19_df[:10]['language'].to_list(), lw_19_df[:10]['count'].to_list()\n",
    "        /(num_rows_19 - df_19.LanguageDesireNextYear.isnull().sum()), color = \"purple\")\n",
    "ax3.tick_params('x', labelrotation=90)\n",
    "ax3.set_title(\"2019\")\n",
    "ax3.set_ylim([0, 0.6])\n",
    "ax3.grid()\n",
    "\n",
    "ax4.bar(lw_20_df[:10]['language'].to_list(), lw_20_df[:10]['count'].to_list()\n",
    "        /(num_rows_20 - df_20.LanguageDesireNextYear.isnull().sum()), color = \"green\")\n",
    "ax4.tick_params('x', labelrotation=90)\n",
    "ax4.set_title(\"2020\")\n",
    "ax4.set_ylim([0, 0.6])\n",
    "ax4.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5.** Group respondent according to non-professional characteristics\n",
    "\n",
    "For this parte of the analysis we willconsider the datasets for all the years.\n",
    "\n",
    "Let's start with Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The title of the column changes over the years\n",
    "count_vals_13 = df_13['What Country or Region do you live in?'].value_counts() #2013\n",
    "count_vals_14 = df_14['What Country do you live in?'].value_counts() #2014\n",
    "count_vals_15 = df_15.Country.value_counts() #2015\n",
    "count_vals_16 = df_16.country.value_counts() #2016\n",
    "count_vals_17 = df_17.Country.value_counts() #2017\n",
    "count_vals_18 = df_18.Country.value_counts() #2018\n",
    "count_vals_19 = df_19.Country.value_counts() #2019\n",
    "count_vals_20 = df_20.Country.value_counts() #2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of the first 10 countries in count_vals\n",
    "# Split in two to improve readability of labels\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "fig.suptitle(\"Country (1/2)\")\n",
    "fig.set_figheight(9) \n",
    "fig.set_figwidth(14)\n",
    "\n",
    "(count_vals_13[:10]/(num_rows_13 - df_13['What Country or Region do you live in?'].isnull().sum())).plot(ax=ax1, kind=\"bar\")\n",
    "ax1.set_title(\"2013\")\n",
    "ax1.set_ylim([0, 0.35])\n",
    "ax1.grid()\n",
    "\n",
    "(count_vals_14[:10]/(num_rows_14 - df_14['What Country do you live in?'].isnull().sum())).plot(ax=ax2, kind=\"bar\")\n",
    "ax2.set_title(\"2014\")\n",
    "ax2.set_ylim([0, 0.35])\n",
    "ax2.grid()\n",
    "\n",
    "(count_vals_15[:10]/(num_rows_15 - df_15.Country.isnull().sum())).plot(ax=ax3, kind=\"bar\")\n",
    "ax3.set_title(\"2015\")\n",
    "ax3.set_ylim([0, 0.35])\n",
    "ax3.grid()\n",
    "\n",
    "(count_vals_16[:10]/(num_rows_16 - df_16.country.isnull().sum())).plot(ax=ax4, kind=\"bar\");\n",
    "ax4.set_title(\"2016\")\n",
    "ax4.set_ylim([0, 0.35])\n",
    "ax4.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in two to inprove readibility of lables\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "fig.suptitle(\"Country (2/2)\")\n",
    "fig.set_figheight(9) \n",
    "fig.set_figwidth(14)\n",
    "\n",
    "(count_vals_17[:10]/(num_rows_17 - df_17.Country.isnull().sum())).plot(ax=ax1, kind=\"bar\")\n",
    "ax1.set_title(\"2017\")\n",
    "ax1.set_ylim([0, 0.35])\n",
    "ax1.grid()\n",
    "\n",
    "(count_vals_18[:10]/(num_rows_18 - df_18.Country.isnull().sum())).plot(ax=ax2, kind=\"bar\")\n",
    "ax2.set_title(\"2018\")\n",
    "ax2.set_ylim([0, 0.35])\n",
    "ax2.grid()\n",
    "\n",
    "(count_vals_19[:10]/(num_rows_19 - df_19.Country.isnull().sum())).plot(ax=ax3, kind=\"bar\");\n",
    "ax3.set_title(\"2019\")\n",
    "ax3.set_ylim([0, 0.35])\n",
    "ax3.grid();\n",
    "\n",
    "(count_vals_20[:10]/(num_rows_20 - df_20.Country.isnull().sum())).plot(ax=ax4, kind=\"bar\");\n",
    "ax4.set_title(\"2020\")\n",
    "ax4.set_ylim([0, 0.35])\n",
    "ax4.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at information about gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2013 does not include information about gender in results\n",
    "gend_vals_14 = df_14['What is your gender?'].value_counts() #2014\n",
    "gend_vals_15 = df_15.Gender.value_counts() #2015\n",
    "gend_vals_16 = df_16.gender.value_counts() #2016\n",
    "gend_vals_17 = df_17.Gender.value_counts() #2017\n",
    "gend_vals_18 = df_18.Gender.value_counts() #2018\n",
    "gend_vals_19 = df_19.Gender.value_counts() #2019\n",
    "gend_vals_20 = df_20.Gender.value_counts() #2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of the proportion of the top 5 values for the individuals in gend_vals\n",
    "# Splitting to improve readability\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "fig.suptitle(\"Gender (1/2)\")\n",
    "fig.set_figheight(9) \n",
    "fig.set_figwidth(14)\n",
    "\n",
    "(gend_vals_14[:5]/(num_rows_14 - df_14['What is your gender?'].isnull().sum())).plot(ax=ax1, kind=\"bar\")\n",
    "ax1.set_title(\"2014\")\n",
    "ax1.set_ylim([0, 0.95])\n",
    "ax1.grid()\n",
    "\n",
    "(gend_vals_15[:5]/(num_rows_15 - df_15.Gender.isnull().sum())).plot(ax=ax2, kind=\"bar\")\n",
    "ax2.set_title(\"2015\")\n",
    "ax2.set_ylim([0, 0.95])\n",
    "ax2.grid()\n",
    "\n",
    "(gend_vals_16[:5]/(num_rows_16 - df_16.gender.isnull().sum())).plot(ax=ax3, kind=\"bar\")\n",
    "ax3.set_title(\"2016\")\n",
    "ax3.set_ylim([0, 0.95])\n",
    "ax3.grid()\n",
    "\n",
    "(gend_vals_17[:5]/(num_rows_17 - df_17.Gender.isnull().sum())).plot(ax=ax4, kind=\"bar\")\n",
    "ax4.set_title(\"2017\")\n",
    "ax4.set_ylim([0, 0.95])\n",
    "ax4.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting to improve readability\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.suptitle(\"Gender (2/2)\")\n",
    "fig.set_figheight(9) \n",
    "fig.set_figwidth(10.5)\n",
    "\n",
    "(gend_vals_18[:5]/(num_rows_18 - df_18.Gender.isnull().sum())).plot(ax=ax1, kind=\"bar\");\n",
    "ax1.set_title(\"2018\")\n",
    "ax1.set_ylim([0, 0.95])\n",
    "ax1.grid();\n",
    "\n",
    "(gend_vals_19[:5]/(num_rows_19 - df_19.Gender.isnull().sum())).plot(ax=ax2, kind=\"bar\")\n",
    "ax2.set_title(\"2019\")\n",
    "ax2.set_ylim([0, 0.95])\n",
    "ax2.grid()\n",
    "\n",
    "(gend_vals_20[:5]/(num_rows_20 - df_20.Gender.isnull().sum())).plot(ax=ax3, kind=\"bar\");\n",
    "ax3.set_title(\"2020\")\n",
    "ax3.set_ylim([0, 0.95])\n",
    "ax3.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate and show Male/Female percentages over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_male = []\n",
    "perc_female = []\n",
    "\n",
    "perc_male.append((gend_vals_14[0]/(num_rows_14 - df_14['What is your gender?'].isnull().sum()))*100)\n",
    "perc_male.append((gend_vals_15[0]/(num_rows_15 - df_15.Gender.isnull().sum()))*100)\n",
    "perc_male.append((gend_vals_16[0]/(num_rows_16 - df_16.gender.isnull().sum()))*100)\n",
    "perc_male.append((gend_vals_17[0]/(num_rows_17 - df_17.Gender.isnull().sum()))*100)\n",
    "perc_male.append((gend_vals_18[0]/(num_rows_18 - df_18.Gender.isnull().sum()))*100)\n",
    "perc_male.append((gend_vals_19[0]/(num_rows_19 - df_19.Gender.isnull().sum()))*100)\n",
    "perc_male.append((gend_vals_20[0]/(num_rows_20 - df_20.Gender.isnull().sum()))*100)\n",
    "\n",
    "perc_female.append((gend_vals_14[1]/(num_rows_14 - df_14['What is your gender?'].isnull().sum()))*100)\n",
    "perc_female.append((gend_vals_15[1]/(num_rows_15 - df_15.Gender.isnull().sum()))*100)\n",
    "perc_female.append((gend_vals_16[1]/(num_rows_16 - df_16.gender.isnull().sum()))*100)\n",
    "perc_female.append((gend_vals_17[1]/(num_rows_17 - df_17.Gender.isnull().sum()))*100)\n",
    "perc_female.append((gend_vals_18[1]/(num_rows_18 - df_18.Gender.isnull().sum()))*100)\n",
    "perc_female.append((gend_vals_19[1]/(num_rows_19 - df_19.Gender.isnull().sum()))*100)\n",
    "perc_female.append((gend_vals_20[1]/(num_rows_20 - df_20.Gender.isnull().sum()))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gend_perc = pd.DataFrame({'Male': perc_male,\n",
    "                             'Female': perc_female},\n",
    "                              index=[2014, 2015, 2016, 2017, 2018, 2019, 2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gend_perc.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First order polynomial to fit data\n",
    "coefficients_male, residuals_male, _,_,_ = np.polyfit(df_gend_perc.index.array,df_gend_perc.Male,1, full=True)\n",
    "coefficients_female, residuals_female, _,_,_ = np.polyfit(df_gend_perc.index.array,df_gend_perc.Female,1, full=True)\n",
    "\n",
    "# Accuracy of the linear predictors\n",
    "mse_male = residuals_male[0]/(df_gend_perc.index.max() - df_gend_perc.index.min())\n",
    "nrmse_male = np.sqrt(mse_male)/(df_gend_perc.Male.max() - df_gend_perc.Male.min())\n",
    "mse_female = residuals_female[0]/(df_gend_perc.index.max() - df_gend_perc.index.min())\n",
    "nrmse_female = np.sqrt(mse_female)/(df_gend_perc.Female.max() - df_gend_perc.Female.min())\n",
    "\n",
    "print('Slope - Male: ' + str(coefficients_male[0]) + '; Female: ' + str(coefficients_female[0]))\n",
    "print('NRMSE - Male: ' + str(nrmse_male)+ '; Female: ' + str(nrmse_female))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot, including trendlines\n",
    "ax = df_gend_perc.plot(grid=True, figsize = (10,7),\n",
    "                  xlabel='Year', ylabel='Percentage',\n",
    "                  title='Gender of the Stack Overflow survey respondents');\n",
    "\n",
    "# Extrapolate linear models\n",
    "xx = [x for x in (df_gend_perc.index.array)]\n",
    "\n",
    "yy_m = [coefficients_male[0]*x + coefficients_male[1] for x in (df_gend_perc.index.array)]\n",
    "yy_f = [coefficients_female[0]*x + coefficients_female[1] for x in (df_gend_perc.index.array)]\n",
    "\n",
    "\n",
    "ax.plot(xx,yy_m,'--')\n",
    "ax.plot(xx,yy_f,'--')\n",
    "ax.legend(['Male', 'Female', 'Male trend', 'Female trend']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot, with extended trendlines\n",
    "ax = df_gend_perc.plot(grid=True, figsize = (10,7),\n",
    "                  xlabel='Year', ylabel='Percentage',\n",
    "                  title='Gender of the Stack Overflow survey respondents - extended trendlines');\n",
    "\n",
    "# Extend predictions a year for an even distribution\n",
    "x_ext = int((50 - coefficients_male[1])/coefficients_male[0])+5\n",
    "\n",
    "xx.append(x_ext)\n",
    "yy_m.append(coefficients_male[0]*x_ext + coefficients_male[1])\n",
    "yy_f.append(coefficients_female[0]*x_ext + coefficients_female[1])\n",
    "\n",
    "\n",
    "ax.plot(xx,yy_m,'--')\n",
    "ax.plot(xx,yy_f,'--')\n",
    "ax.grid(b=True)\n",
    "ax.legend(['Male', 'Female', 'Male trend', 'Female trend']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, note that 2016 included a specific \"women_on_teams\" columns\n",
    "wot_16 = df_16.women_on_team.value_counts()\n",
    "\n",
    "(wot_16*100/(num_rows_16 - df_16.women_on_team.isnull().sum())).plot(kind=\"bar\", grid=True, figsize = (10,7),\n",
    "                                                                 title='% of Women in a team (2016)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a look at ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2013/17 does not include information about ethnicity in results\n",
    "ethn_vals_17 = df_17.Race.value_counts() #2017\n",
    "ethn_vals_18 = df_18.RaceEthnicity.value_counts() #2018\n",
    "ethn_vals_19 = df_19.Ethnicity.value_counts() #2019\n",
    "ethn_vals_20 = df_20.Ethnicity.value_counts() #2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of the proportion of the top 5 values for the individuals in ethn_vals\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "fig.suptitle(\"Ethnicity\")\n",
    "fig.set_figheight(9) \n",
    "fig.set_figwidth(14)\n",
    "\n",
    "(ethn_vals_17[:5]/(num_rows_17 - df_17.Race.isnull().sum())).plot(ax=ax1, kind=\"bar\")\n",
    "ax1.set_title(\"2017\")\n",
    "ax1.set_ylim([0, 0.80])\n",
    "ax1.grid()\n",
    "\n",
    "(ethn_vals_18[:5]/(num_rows_18 - df_18.RaceEthnicity.isnull().sum())).plot(ax=ax2, kind=\"bar\")\n",
    "ax2.set_title(\"2018\")\n",
    "ax2.set_ylim([0, 0.80])\n",
    "ax2.grid()\n",
    "\n",
    "(ethn_vals_19[:5]/(num_rows_19 - df_19.Ethnicity.isnull().sum())).plot(ax=ax3, kind=\"bar\")\n",
    "ax3.set_title(\"2019\")\n",
    "ax3.set_ylim([0, 0.80])\n",
    "ax3.grid()\n",
    "\n",
    "(ethn_vals_20[:5]/(num_rows_20 - df_20.Ethnicity.isnull().sum())).plot(ax=ax4, kind=\"bar\")\n",
    "ax4.set_title(\"2020\")\n",
    "ax4.set_ylim([0, 0.80])\n",
    "ax4.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
