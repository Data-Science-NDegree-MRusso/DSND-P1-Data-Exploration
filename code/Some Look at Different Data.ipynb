{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<h2 id='part1'>Compare the Data - 2</h2>\n",
    "\n",
    "\n",
    "Compare 2017 and 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's read in the data and necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "\n",
    "df_17 = pd.read_csv('../data/stack_overflow_2017/survey_results_public.csv') #Uncomment for 2017\n",
    "df_18 = pd.read_csv('../data/stack_overflow_2018/survey_results_public.csv') #Uncomment for 2017\n",
    "df_19 = pd.read_csv('../data/stack_overflow_2019/survey_results_public.csv') #Uncomment for 2017\n",
    "df_20 = pd.read_csv('../data/stack_overflow_2020/survey_results_public.csv') #Uncomment for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1.** # of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_17 = df_17.shape[0] # rows, 2017\n",
    "num_cols_17 = df_17.shape[1] # columns, 2017\n",
    "\n",
    "num_rows_18 = df_18.shape[0] # rows, 2018\n",
    "num_cols_18 = df_18.shape[1] # columns, 2018\n",
    "\n",
    "num_rows_19 = df_19.shape[0] # rows, 2019\n",
    "num_cols_19 = df_19.shape[1] # columns, 2019\n",
    "\n",
    "num_rows_20 = df_20.shape[0] # rows, 2020\n",
    "num_cols_20 = df_20.shape[1] # columns, 2020\n",
    "\n",
    "print(\"Year 2017 - Rows in the dataset: \", num_rows_17, \"; Colums in the dataset: \", num_cols_17)\n",
    "print(\"Year 2018 - Rows in the dataset: \", num_rows_18, \"; Colums in the dataset: \", num_cols_18)\n",
    "print(\"Year 2019 - Rows in the dataset: \", num_rows_19, \"; Colums in the dataset: \", num_cols_19)\n",
    "print(\"Year 2020 - Rows in the dataset: \", num_rows_20, \"; Colums in the dataset: \", num_cols_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** What is the percentage of `null` in the various years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_per_17 = df_17.isnull().sum().sum()/(num_rows_17*num_cols_17)\n",
    "null_per_18 = df_18.isnull().sum().sum()/(num_rows_18*num_cols_18)\n",
    "null_per_19 = df_19.isnull().sum().sum()/(num_rows_19*num_cols_19)\n",
    "null_per_20 = df_20.isnull().sum().sum()/(num_rows_20*num_cols_20)\n",
    "\n",
    "print (\"Year 2017 - Percentage of Null: \", \"{:.2f}\".format(null_per_17*100), \"%\")\n",
    "print (\"Year 2018 - Percentage of Null: \", \"{:.2f}\".format(null_per_18*100), \"%\")\n",
    "print (\"Year 2019 - Percentage of Null: \", \"{:.2f}\".format(null_per_19*100), \"%\")\n",
    "print (\"Year 2020 - Percentage of Null: \", \"{:.2f}\".format(null_per_20*100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (2017)** - `It's better to ship now and optimize later`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipit_vals_17 = df_17.ShipIt.value_counts() #2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart of the proportion of individuals in each preference \n",
    "(shipit_vals_17/(num_rows_17 - df_17.ShipIt.isnull().sum())).plot(kind=\"bar\");\n",
    "plt.title(\"Ship It Now! (2017)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. (2017)** - `Tab or Spaces?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabspac_vals_17 = df_17.TabsSpaces.value_counts() #2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart of the proportion of individuals in each preference \n",
    "(tabspac_vals_17/(num_rows_17 - df_17.TabsSpaces.isnull().sum())).plot(kind=\"bar\");\n",
    "plt.title(\"Tab VS. Spaces (2017)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** Function to be used to parse the language columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_count(df, col1, col2, separator):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - the pandas dataframe you want to search\n",
    "    col1 - the column name you want to look through\n",
    "    col2 - the column you want to count values from\n",
    "    look_for - a list of strings you want to search for in each row of df[col]\n",
    "    separator - separator between strings (comma, semicolon etc.)\n",
    "\n",
    "    OUTPUT:\n",
    "    new_df - a dataframe of each look_for with the count of how often it shows up\n",
    "    items_list - a list of the different items that were identified parsing the dataframe\n",
    "    '''\n",
    "    new_df = defaultdict(int)\n",
    "    items_list = [] \n",
    "\n",
    "    # loop through rows\n",
    "    for idx in range(df.shape[0]):\n",
    "        # Split the string to separate the various languages used by the responder (if > 1)\n",
    "        langs = df[col1][idx].split(separator)\n",
    "        # Loop in the list of items\n",
    "        for idy in range(len(langs)):\n",
    "            # Update counts in the dataframe\n",
    "            val = langs[idy]\n",
    "            new_df[val] += int(df[col2][idx])\n",
    "            # If not detected before update list            \n",
    "            if (not(val in items_list)):\n",
    "                items_list.append(val)\n",
    "                \n",
    "    new_df = pd.DataFrame(pd.Series(new_df)).reset_index()\n",
    "    new_df.columns = [col1, col2]\n",
    "    new_df.sort_values('count', ascending=False, inplace=True)\n",
    "    return new_df, items_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Languages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_used_17 = df_17.HaveWorkedLanguage.value_counts() #2017\n",
    "lang_used_18 = df_18.LanguageWorkedWith.value_counts() #2018\n",
    "lang_used_19 = df_19.LanguageWorkedWith.value_counts() #2019\n",
    "lang_used_20 = df_20.LanguageWorkedWith.value_counts() #2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_17 = lang_used_17.reset_index()\n",
    "lu_18 = lang_used_18.reset_index()\n",
    "lu_19 = lang_used_19.reset_index()\n",
    "lu_20 = lang_used_20.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_17.rename(columns={'index': 'language', 'HaveWorkedLanguage': 'count'}, inplace=True)\n",
    "lu_18.rename(columns={'index': 'language', 'LanguageWorkedWith': 'count'}, inplace=True)\n",
    "lu_19.rename(columns={'index': 'language', 'LanguageWorkedWith': 'count'}, inplace=True)\n",
    "lu_20.rename(columns={'index': 'language', 'LanguageWorkedWith': 'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_17_df, worked_languages_17 = total_count(lu_17, 'language', 'count', '; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_18_df, worked_languages_18 = total_count(lu_18, 'language', 'count', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_19_df, worked_languages_19 = total_count(lu_19, 'language', 'count', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_20_df, worked_languages_20 = total_count(lu_20, 'language', 'count', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of the proportion of the top 10 languages/combinations for the individuals in count_vals\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "fig.suptitle(\"Languages Used\")\n",
    "fig.set_figheight(19.2) \n",
    "fig.set_figwidth(12.8)\n",
    "\n",
    "ax1.bar(lu_17_df[:10]['language'].to_list(), lu_17_df[:10]['count'].to_list()\n",
    "        /(num_rows_17 - df_17.HaveWorkedLanguage.isnull().sum()))\n",
    "ax1.tick_params('x', labelrotation=90)\n",
    "ax1.set_title(\"2017\")\n",
    "ax1.set_ylim([0, 0.8])\n",
    "ax1.grid()\n",
    "\n",
    "ax2.bar(lu_18_df[:10]['language'].to_list(), lu_18_df[:10]['count'].to_list()\n",
    "        /(num_rows_18 - df_18.LanguageWorkedWith.isnull().sum()), color = \"orange\")\n",
    "ax2.tick_params('x', labelrotation=90)\n",
    "ax2.set_title(\"2018\")\n",
    "ax2.set_ylim([0, 0.8])\n",
    "ax2.grid()\n",
    "\n",
    "ax3.bar(lu_19_df[:10]['language'].to_list(), lu_19_df[:10]['count'].to_list()\n",
    "        /(num_rows_19 - df_19.LanguageWorkedWith.isnull().sum()), color = \"purple\")\n",
    "ax3.tick_params('x', labelrotation=90)\n",
    "ax3.set_title(\"2019\")\n",
    "ax3.set_ylim([0, 0.8])\n",
    "ax3.grid()\n",
    "\n",
    "ax4.bar(lu_20_df[:10]['language'].to_list(), lu_20_df[:10]['count'].to_list()\n",
    "        /(num_rows_20 - df_20.LanguageWorkedWith.isnull().sum()), color = \"green\")\n",
    "ax4.tick_params('x', labelrotation=90)\n",
    "ax4.set_title(\"2020\")\n",
    "ax4.set_ylim([0, 0.8])\n",
    "ax4.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Languages Wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_wanted_17 = df_17.WantWorkLanguage.value_counts() #2017\n",
    "lang_wanted_18 = df_18.LanguageDesireNextYear.value_counts() #2018\n",
    "lang_wanted_19 = df_19.LanguageDesireNextYear.value_counts() #2019\n",
    "lang_wanted_20 = df_20.LanguageDesireNextYear.value_counts() #2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_17 = lang_wanted_17.reset_index()\n",
    "lw_18 = lang_wanted_18.reset_index()\n",
    "lw_19 = lang_wanted_19.reset_index()\n",
    "lw_20 = lang_wanted_20.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_17.rename(columns={'index': 'language', 'WantWorkLanguage': 'count'}, inplace=True)\n",
    "lw_18.rename(columns={'index': 'language', 'LanguageDesireNextYear': 'count'}, inplace=True)\n",
    "lw_19.rename(columns={'index': 'language', 'LanguageDesireNextYear': 'count'}, inplace=True)\n",
    "lw_20.rename(columns={'index': 'language', 'LanguageDesireNextYear': 'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_17_df, wanted_languages_17 = total_count(lw_17, 'language', 'count', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_18_df, wanted_languages_18 = total_count(lw_18, 'language', 'count', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_19_df, wanted_languages_19 = total_count(lw_19, 'language', 'count', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_20_df, wanted_languages_20 = total_count(lw_20, 'language', 'count', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of the proportion of the top 10 languages/combinations for the individuals in count_vals\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "fig.suptitle(\"Languages Wanted\")\n",
    "fig.set_figheight(19.2) \n",
    "fig.set_figwidth(12.8)\n",
    "\n",
    "ax1.bar(lw_17_df[:10]['language'].to_list(), lw_17_df[:10]['count'].to_list()\n",
    "        /(num_rows_17 - df_17.WantWorkLanguage.isnull().sum()))\n",
    "ax1.tick_params('x', labelrotation=90)\n",
    "ax1.set_title(\"2017\")\n",
    "ax1.set_ylim([0, 0.6])\n",
    "ax1.grid()\n",
    "\n",
    "ax2.bar(lw_18_df[:10]['language'].to_list(), lw_18_df[:10]['count'].to_list()\n",
    "        /(num_rows_18 - df_18.LanguageDesireNextYear.isnull().sum()), color = \"orange\")\n",
    "ax2.tick_params('x', labelrotation=90)\n",
    "ax2.set_title(\"2018\")\n",
    "ax2.set_ylim([0, 0.6])\n",
    "ax2.grid()\n",
    "\n",
    "ax3.bar(lw_19_df[:10]['language'].to_list(), lw_19_df[:10]['count'].to_list()\n",
    "        /(num_rows_19 - df_19.LanguageDesireNextYear.isnull().sum()), color = \"purple\")\n",
    "ax3.tick_params('x', labelrotation=90)\n",
    "ax3.set_title(\"2019\")\n",
    "ax3.set_ylim([0, 0.6])\n",
    "ax3.grid()\n",
    "\n",
    "ax4.bar(lw_20_df[:10]['language'].to_list(), lw_20_df[:10]['count'].to_list()\n",
    "        /(num_rows_20 - df_20.LanguageDesireNextYear.isnull().sum()), color = \"green\")\n",
    "ax4.tick_params('x', labelrotation=90)\n",
    "ax4.set_title(\"2020\")\n",
    "ax4.set_ylim([0, 0.6])\n",
    "ax4.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
